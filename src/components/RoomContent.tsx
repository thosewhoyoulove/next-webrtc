// src/components/RoomContent.tsx
"use client";

import { useEffect, useRef, useState } from "react";
import { useRouter } from "next/router";
import io, { Socket } from "socket.io-client";
import { useSubtitleRecognizer } from "@/hooks/useSubtitleRecognizer";

export default function RoomContent() {
    const router = useRouter();
    const { id: roomId } = router.query;

    // è§†é¢‘ç›¸å…³çš„ ref
    const localVideoRef = useRef<HTMLVideoElement>(null); // æœ¬åœ°è§†é¢‘å…ƒç´ å¼•ç”¨
    const remoteVideoRef = useRef<HTMLVideoElement>(null); // è¿œç¨‹è§†é¢‘å…ƒç´ å¼•ç”¨

    // WebRTC ç›¸å…³çš„ ref
    const socketRef = useRef<Socket | null>(null); // Socket.io è¿æ¥å¼•ç”¨
    const peerRef = useRef<RTCPeerConnection | null>(null); // WebRTC è¿æ¥å¼•ç”¨

    // UI çŠ¶æ€ç®¡ç†
    const [isMuted, setIsMuted] = useState(false); // é™éŸ³çŠ¶æ€
    const [videoEnabled, setVideoEnabled] = useState(true); // è§†é¢‘å¼€å¯çŠ¶æ€
    const [peerLeft, setPeerLeft] = useState(false); // å¯¹æ–¹æ˜¯å¦ç¦»å¼€
    const [recording, setRecording] = useState(false); // å½•åˆ¶çŠ¶æ€

    // å½•åˆ¶ç›¸å…³çš„ ref
    const mediaRecorderRef = useRef<MediaRecorder | null>(null); // åª’ä½“å½•åˆ¶å™¨å¼•ç”¨
    const recordedChunksRef = useRef<Blob[]>([]); // å½•åˆ¶çš„æ•°æ®å—
    const canvasRef = useRef<HTMLCanvasElement | null>(null); // ç”»å¸ƒå¼•ç”¨
    const animationFrameRef = useRef<number | undefined>(undefined); // åŠ¨ç”»å¸§å¼•ç”¨

    // è¯­éŸ³è¯†åˆ« Hook
    const { subtitle, startRecognition, stopRecognition } = useSubtitleRecognizer("zh-CN");

    // æ ¸å¿ƒçš„ WebRTC è¿æ¥é€»è¾‘
    useEffect(() => {
        if (!roomId) return;
        // ä¿å­˜æœ€è¿‘çš„æˆ¿é—´ID
        localStorage.setItem("lastRoomId", roomId as string);

        // è¿æ¥ä¿¡ä»¤æœåŠ¡å™¨
        socketRef.current = io("https://webrtc.peterroe.me/");

        // è·å–æœ¬åœ°åª’ä½“æµ
        navigator.mediaDevices
            .getUserMedia({
                video: {
                    width: { ideal: 1280 },
                    height: { ideal: 720 },
                    frameRate: { ideal: 30 },
                },
                audio: true,
            })
            .then(stream => {
                // è®¾ç½®æœ¬åœ°è§†é¢‘æµ
                if (localVideoRef.current) localVideoRef.current.srcObject = stream;

                // åˆ›å»º WebRTC è¿æ¥
                peerRef.current = new RTCPeerConnection();
                // æ·»åŠ æœ¬åœ°åª’ä½“è½¨é“åˆ°è¿æ¥ä¸­
                stream.getTracks().forEach(track => peerRef.current?.addTrack(track, stream));

                // å¤„ç†è¿œç¨‹è§†é¢‘æµ
                peerRef.current.ontrack = event => {
                    if (remoteVideoRef.current) remoteVideoRef.current.srcObject = event.streams[0];
                };

                // ICE å€™é€‰å¤„ç†
                peerRef.current.onicecandidate = event => {
                    if (event.candidate) socketRef.current?.emit("ice-candidate", { candidate: event.candidate, roomId });
                };

                // åŠ å…¥æˆ¿é—´
                socketRef.current?.emit("join-room", roomId);

                // å¤„ç†æ–°ç”¨æˆ·åŠ å…¥
                socketRef.current?.on("user-joined", async () => {
                    const offer = await peerRef.current?.createOffer();
                    await peerRef.current?.setLocalDescription(offer);
                    socketRef.current?.emit("offer", { offer, roomId });
                });

                // å¤„ç†æ”¶åˆ°çš„ offer
                socketRef.current?.on("offer", async ({ offer }) => {
                    await peerRef.current?.setRemoteDescription(new RTCSessionDescription(offer));
                    const answer = await peerRef.current?.createAnswer();
                    await peerRef.current?.setLocalDescription(answer);
                    socketRef.current?.emit("answer", { answer, roomId });
                });

                // å¤„ç†æ”¶åˆ°çš„ answer
                socketRef.current?.on("answer", ({ answer }) => {
                    peerRef.current?.setRemoteDescription(new RTCSessionDescription(answer));
                });

                // å¤„ç† ICE å€™é€‰
                socketRef.current?.on("ice-candidate", ({ candidate }) => {
                    peerRef.current?.addIceCandidate(new RTCIceCandidate(candidate));
                });

                // å¤„ç†ç”¨æˆ·ç¦»å¼€
                socketRef.current?.on("user-left", () => {
                    setPeerLeft(true);
                    if (remoteVideoRef.current) {
                        remoteVideoRef.current.srcObject = null;
                    }
                });
            });

        // æ¸…ç†å‡½æ•°
        return () => {
            socketRef.current?.emit("leave-room", roomId);
            peerRef.current?.close();
        };
    }, [roomId]);

    // éŸ³é¢‘æ§åˆ¶ï¼šåˆ‡æ¢é™éŸ³çŠ¶æ€
    const toggleMute = () => {
        const stream = localVideoRef.current?.srcObject as MediaStream;
        const newMuted = !isMuted;
        stream?.getAudioTracks().forEach(track => (track.enabled = !newMuted));
        setIsMuted(newMuted);
        socketRef.current?.emit("toggle-audio", { isAudioEnabled: newMuted });
    };

    // è§†é¢‘æ§åˆ¶ï¼šåˆ‡æ¢è§†é¢‘å¼€å¯çŠ¶æ€
    const toggleVideo = () => {
        const stream = localVideoRef.current?.srcObject as MediaStream;
        stream?.getVideoTracks().forEach(track => (track.enabled = !videoEnabled));
        setVideoEnabled(!videoEnabled);
    };

    // å¤åˆ¶æˆ¿é—´IDåˆ°å‰ªè´´æ¿
    const copyToClipboard = () => {
        if (roomId) {
            navigator.clipboard.writeText(roomId as string).then(() => {
                alert("æˆ¿é—´ ID å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼");
            });
        }
    };

    // ç¦»å¼€ä¼šè®®
    const leaveMeeting = () => {
        socketRef.current?.emit("leave-room", roomId);
        peerRef.current?.close();
        router.push("/");
    };

    // å¼€å§‹å½•åˆ¶ä¼šè®®
    const startCanvasRecording = () => {
        const localVideo = localVideoRef.current;
        const remoteVideo = remoteVideoRef.current;
        if (!localVideo || !remoteVideo) return alert("è§†é¢‘è¿˜æ²¡å‡†å¤‡å¥½");

        // å¼€å§‹è¯­éŸ³è¯†åˆ«
        startRecognition();

        // åˆ›å»ºç”»å¸ƒç”¨äºåˆæˆè§†é¢‘
        const canvas = document.createElement("canvas");
        canvas.width = 1280;
        canvas.height = 720;
        const ctx = canvas.getContext("2d");
        canvasRef.current = canvas;

        // å®šä¹‰æ¯ä¸€å¸§çš„ç»˜åˆ¶å‡½æ•°
        const drawFrame = () => {
            if (!ctx) return;
            ctx.clearRect(0, 0, 1280, 720);

            // ç»˜åˆ¶æœ¬åœ°å’Œè¿œç¨‹è§†é¢‘
            ctx.drawImage(localVideo, 0, 0, 640, 720);
            ctx.drawImage(remoteVideo, 640, 0, 640, 720);

            // æ·»åŠ å­—å¹•èƒŒæ™¯
            ctx.fillStyle = "rgba(0, 0, 0, 0.5)";
            ctx.fillRect(0, 680, 1280, 40);

            // ç»˜åˆ¶å­—å¹•
            ctx.fillStyle = "white";
            ctx.font = "bold 24px Arial";
            ctx.textAlign = "center";
            ctx.fillText(subtitle, 640, 710);

            // è¯·æ±‚ä¸‹ä¸€å¸§
            animationFrameRef.current = requestAnimationFrame(drawFrame);
        };

        drawFrame();

        // ä»ç”»å¸ƒåˆ›å»ºè§†é¢‘æµ
        const canvasStream = canvas.captureStream(30);

        // åˆ›å»ºéŸ³é¢‘æµ
        const audioStream = new MediaStream();
        const localStream = localVideo.srcObject as MediaStream;
        const remoteStream = remoteVideo.srcObject as MediaStream;

        // åˆå¹¶æœ¬åœ°å’Œè¿œç¨‹çš„éŸ³é¢‘è½¨é“
        localStream.getAudioTracks().forEach(track => audioStream.addTrack(track));
        remoteStream.getAudioTracks().forEach(track => audioStream.addTrack(track));

        // åˆ›å»ºæœ€ç»ˆçš„åª’ä½“æµï¼ˆéŸ³é¢‘+è§†é¢‘ï¼‰
        const combinedStream = new MediaStream([...audioStream.getAudioTracks(), ...canvasStream.getVideoTracks()]);

        // é…ç½®åª’ä½“å½•åˆ¶å™¨
        const mediaRecorder = new MediaRecorder(combinedStream, {
            mimeType: "video/webm;codecs=vp9,opus",
        });

        mediaRecorderRef.current = mediaRecorder;
        recordedChunksRef.current = [];

        // å¤„ç†å½•åˆ¶æ•°æ®
        mediaRecorder.ondataavailable = event => {
            if (event.data.size > 0) recordedChunksRef.current.push(event.data);
        };

        // å½•åˆ¶ç»“æŸæ—¶çš„å¤„ç†
        mediaRecorder.onstop = () => {
            cancelAnimationFrame(animationFrameRef.current!);
            const blob = new Blob(recordedChunksRef.current, { type: "video/webm" });
            const url = URL.createObjectURL(blob);
            const a = document.createElement("a");
            a.href = url;
            a.download = `recording-${Date.now()}.webm`;
            a.click();
        };

        // å¼€å§‹å½•åˆ¶
        mediaRecorder.start();
        setRecording(true);
    };

    // åœæ­¢å½•åˆ¶
    const stopRecording = () => {
        mediaRecorderRef.current?.stop();
        setRecording(false);
        stopRecognition();
    };

    return (
        <div className="flex flex-col items-center justify-center min-h-screen bg-gray-900 text-white px-4 py-8">
            {/* å¯¹æ–¹ç¦»å¼€æç¤º */}
            <h1 className="mb-4 text-center">{peerLeft && <p className="text-red-500">The other user has left the meeting.</p>}</h1>

            {/* æˆ¿é—´ä¿¡æ¯åŒºåŸŸ */}
            <div className="flex flex-col sm:flex-row items-center gap-4 mb-6 w-full max-w-3xl justify-center text-center sm:text-left">
                <h1 className="font-bold text-xl sm:text-2xl break-words">Room ID: {roomId}</h1>
                <button onClick={copyToClipboard} className="bg-blue-500 hover:bg-blue-600 text-white font-bold py-2 px-6 rounded-lg w-full sm:w-auto">
                    Copy Room ID
                </button>
            </div>

            {/* è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ */}
            <div className="grid grid-cols-1 sm:grid-cols-2 gap-4 w-full max-w-4xl">
                {/* æœ¬åœ°è§†é¢‘ */}
                <div className="relative border-2 border-gray-700 rounded-lg overflow-hidden">
                    <p className="absolute top-2 left-2 bg-gray-700 px-2 py-1 text-sm rounded">You {isMuted ? "ğŸ”‡" : "ğŸ”Š"}</p>
                    <video ref={localVideoRef} autoPlay playsInline muted className="w-full h-64 sm:h-72 bg-black" />
                </div>
                {/* è¿œç¨‹è§†é¢‘ */}
                <div className="relative border-2 border-gray-700 rounded-lg overflow-hidden">
                    <p className="absolute top-2 left-2 bg-gray-700 px-2 py-1 text-sm rounded">Peer</p>
                    <video ref={remoteVideoRef} autoPlay playsInline className="w-full h-64 sm:h-72 bg-black" />
                </div>
            </div>

            {/* æ§åˆ¶æŒ‰é’®åŒºåŸŸ */}
            <div className="flex flex-col justify-center sm:flex-row gap-4 mt-6 w-full max-w-4xl">
                <button className="bg-blue-500 hover:bg-blue-600 text-white font-bold py-2 px-6 rounded-lg w-full sm:w-auto" onClick={toggleMute}>
                    {isMuted ? "Unmute" : "Mute"}
                </button>
                <button className="bg-blue-500 hover:bg-blue-600 text-white font-bold py-2 px-6 rounded-lg w-full sm:w-auto" onClick={toggleVideo}>
                    {videoEnabled ? "Turn Off Video" : "Turn On Video"}
                </button>
                <button className="bg-red-500 hover:bg-red-600 text-white font-bold py-2 px-6 rounded-lg w-full sm:w-auto" onClick={leaveMeeting}>
                    Leave Meeting
                </button>
                {!recording ? (
                    <button className="bg-purple-500 hover:bg-purple-600 text-white font-bold py-2 px-6 rounded-lg w-full sm:w-auto" onClick={startCanvasRecording}>
                        Record
                    </button>
                ) : (
                    <button className="bg-yellow-500 hover:bg-yellow-600 text-white font-bold py-2 px-6 rounded-lg w-full sm:w-auto" onClick={stopRecording}>
                        Stop Recording
                    </button>
                )}
            </div>
        </div>
    );
}
